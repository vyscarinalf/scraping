{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4SMu1-lAZLA",
        "outputId": "b506167e-d3d4-4d5b-dec5-9dd465c74f55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "df = pd.read_excel(\"data label.xlsx\")\n",
        "texts = df[\"data\"].astype(str)\n",
        "labels = df[\"label\"]\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "def stem_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    stems = [stemmer.stem(w) for w in tokens]\n",
        "    return \" \".join(stems)\n",
        "\n",
        "df[\"clean\"] = texts.apply(stem_text)\n",
        "\n",
        "X = df[\"clean\"]\n",
        "y = labels\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vuiQGz9BgFM",
        "outputId": "0d6cc3b6-21fa-46a3-bbd0-80ecbf848954"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF"
      ],
      "metadata": {
        "id": "GiFdruYSRTyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer_tfidf = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer_tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer_tfidf.transform(X_test)\n",
        "\n",
        "model_dt = DecisionTreeClassifier(\n",
        "    criterion='entropy',\n",
        "    max_depth=50,\n",
        "    min_samples_split=5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model_dt.fit(X_train_tfidf, y_train)\n",
        "\n",
        "pred1 = model_dt.predict(X_test_tfidf)\n",
        "acc1 = accuracy_score(y_test, pred1)\n",
        "\n",
        "print(\"TF-IDF + Decision Tree\")\n",
        "print(\"Akurasi:\", acc1)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, pred1, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq4F5LkoTNJ6",
        "outputId": "3d4ccc47-1731-4cdf-f1db-df4e3780a702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF + Decision Tree\n",
            "Akurasi: 0.7\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif     0.9375    0.7500    0.8333        20\n",
            "      netral     0.5714    0.3636    0.4444        11\n",
            "     positif     0.5926    0.8421    0.6957        19\n",
            "\n",
            "    accuracy                         0.7000        50\n",
            "   macro avg     0.7005    0.6519    0.6578        50\n",
            "weighted avg     0.7259    0.7000    0.6955        50\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer_tfidf = TfidfVectorizer(\n",
        "    ngram_range=(1, 2),      # unigram + bigram\n",
        "    sublinear_tf=True,       # TF-IDF lebih stabil\n",
        "    min_df=2,                # hilangkan kata terlalu jarang\n",
        "    max_features=10000       # batasi fitur besar supaya tidak overfitting\n",
        ")\n",
        "\n",
        "X_train_tfidf = vectorizer_tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer_tfidf.transform(X_test)\n",
        "\n",
        "model_nb = ComplementNB()\n",
        "model_nb.fit(X_train_tfidf, y_train)\n",
        "\n",
        "pred1 = model_nb.predict(X_test_tfidf)\n",
        "acc1 = accuracy_score(y_test, pred1)\n",
        "\n",
        "print(\"TF-IDF + Naive Bayes\")\n",
        "print(\"Akurasi:\", acc1)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, pred1, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtFOOKtiVltu",
        "outputId": "d4f349a2-6d4b-4d46-d07d-3d34afe19091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF + Naive Bayes\n",
            "Akurasi: 0.82\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif     0.7500    0.9000    0.8182        20\n",
            "      netral     0.8750    0.6364    0.7368        11\n",
            "     positif     0.8889    0.8421    0.8649        19\n",
            "\n",
            "    accuracy                         0.8200        50\n",
            "   macro avg     0.8380    0.7928    0.8066        50\n",
            "weighted avg     0.8303    0.8200    0.8180        50\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer_tfidf = TfidfVectorizer(\n",
        "    ngram_range=(1, 2),\n",
        "    sublinear_tf=True,\n",
        "    min_df=2,\n",
        "    max_df=0.95,\n",
        "    max_features=15000\n",
        ")\n",
        "\n",
        "X_train_tfidf = vectorizer_tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer_tfidf.transform(X_test)\n",
        "\n",
        "# Logistic Regression Tuning\n",
        "model_lr = LogisticRegression(\n",
        "    C=2.0,\n",
        "    max_iter=1000,\n",
        "    solver='liblinear',\n",
        "    class_weight='balanced',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model_lr.fit(X_train_tfidf, y_train)\n",
        "\n",
        "pred3 = model_lr.predict(X_test_tfidf)\n",
        "acc3 = accuracy_score(y_test, pred3)\n",
        "\n",
        "print(\"TF-IDF + Logistic Regression\")\n",
        "print(\"Akurasi:\", acc3)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, pred3, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLYUbGq9V7Al",
        "outputId": "14381bed-a49b-485d-86d9-3b67cb565d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF + Logistic Regression\n",
            "Akurasi: 0.8\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif     0.7200    0.9000    0.8000        20\n",
            "      netral     0.8333    0.4545    0.5882        11\n",
            "     positif     0.8947    0.8947    0.8947        19\n",
            "\n",
            "    accuracy                         0.8000        50\n",
            "   macro avg     0.8160    0.7498    0.7610        50\n",
            "weighted avg     0.8113    0.8000    0.7894        50\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "# SVM Model\n",
        "model_svm = SVC(kernel=\"linear\")       # kernel linear paling umum utk teks\n",
        "model_svm.fit(X_train_tfidf, y_train)\n",
        "\n",
        "pred = model_svm.predict(X_test_tfidf)\n",
        "\n",
        "accuracy = accuracy_score(y_test, pred)\n",
        "\n",
        "print(\"TF-IDF + SVM\")\n",
        "print(\"Akurasi:\", accuracy)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b3GMZoZRoHm",
        "outputId": "07d390ab-f274-4c35-dc17-83e32d2990a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF + SVM\n",
            "Akurasi: 0.8\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.72      0.90      0.80        20\n",
            "      netral       1.00      0.55      0.71        11\n",
            "     positif       0.84      0.84      0.84        19\n",
            "\n",
            "    accuracy                           0.80        50\n",
            "   macro avg       0.85      0.76      0.78        50\n",
            "weighted avg       0.83      0.80      0.80        50\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BoW"
      ],
      "metadata": {
        "id": "zq5fs7mNRgog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer_bow = CountVectorizer(\n",
        "    ngram_range=(1,2),   # unigram + bigram â†’ akurasi naik\n",
        "    min_df=2,            # buang kata sangat jarang\n",
        "    max_df=0.95          # buang kata terlalu sering\n",
        ")\n",
        "X_train_bow = vectorizer_bow.fit_transform(X_train)\n",
        "X_test_bow = vectorizer_bow.transform(X_test)\n",
        "\n",
        "model_nb = MultinomialNB(alpha=0.3)   # alpha dituning untuk akurasi lebih tinggi\n",
        "model_nb.fit(X_train_bow, y_train)\n",
        "\n",
        "pred1 = model_nb.predict(X_test_bow)\n",
        "acc1 = accuracy_score(y_test, pred1)\n",
        "\n",
        "print(\"BoW + Naive Bayes\")\n",
        "print(\"Akurasi:\", acc1)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, pred1, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSdsgMreHGHV",
        "outputId": "50d00718-c180-4194-8529-1e398486ff1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BoW + Naive Bayes\n",
            "Akurasi: 0.76\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif     0.7391    0.8500    0.7907        20\n",
            "      netral     0.8333    0.4545    0.5882        11\n",
            "     positif     0.7619    0.8421    0.8000        19\n",
            "\n",
            "    accuracy                         0.7600        50\n",
            "   macro avg     0.7781    0.7156    0.7263        50\n",
            "weighted avg     0.7685    0.7600    0.7497        50\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer_bow = CountVectorizer(\n",
        "    ngram_range=(1,2),\n",
        "    min_df=2,\n",
        "    max_df=0.95,\n",
        ")\n",
        "\n",
        "X_train_bow = vectorizer_bow.fit_transform(X_train)\n",
        "X_test_bow = vectorizer_bow.transform(X_test)\n",
        "\n",
        "model_dt = DecisionTreeClassifier(\n",
        "    criterion='entropy',\n",
        "    max_depth=50,\n",
        "    min_samples_split=5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model_dt.fit(X_train_bow, y_train)\n",
        "\n",
        "pred1 = model_dt.predict(X_test_bow)\n",
        "acc1 = accuracy_score(y_test, pred1)\n",
        "\n",
        "print(\"BoW + Decision Tree\")\n",
        "print(\"Akurasi:\", acc1)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, pred1, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m3by5diZCLu",
        "outputId": "75877da1-2a24-480e-ef1d-7f808c9b1977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BoW + Decision Tree\n",
            "Akurasi: 0.7\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif     0.8667    0.6500    0.7429        20\n",
            "      netral     0.7143    0.4545    0.5556        11\n",
            "     positif     0.6071    0.8947    0.7234        19\n",
            "\n",
            "    accuracy                         0.7000        50\n",
            "   macro avg     0.7294    0.6664    0.6739        50\n",
            "weighted avg     0.7345    0.7000    0.6943        50\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer_bow = CountVectorizer(\n",
        "    ngram_range=(1,2),\n",
        "    min_df=2,\n",
        "    max_df=0.95,\n",
        ")\n",
        "\n",
        "X_train_bow = vectorizer_bow.fit_transform(X_train)\n",
        "X_test_bow = vectorizer_bow.transform(X_test)\n",
        "\n",
        "model_svm = SVC(kernel=\"linear\")\n",
        "model_svm.fit(X_train_bow, y_train)\n",
        "\n",
        "pred2 = model_svm.predict(X_test_bow)\n",
        "acc2 = accuracy_score(y_test, pred2)\n",
        "\n",
        "print(\"BoW + SVM\")\n",
        "print(\"Akurasi:\", acc2)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO4MHxN-X8j6",
        "outputId": "876014d6-f863-4bab-ed27-5c69c2967e90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BoW + SVM\n",
            "Akurasi: 0.74\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.94      0.75      0.83        20\n",
            "      netral       0.83      0.45      0.59        11\n",
            "     positif       0.61      0.89      0.72        19\n",
            "\n",
            "    accuracy                           0.74        50\n",
            "   macro avg       0.79      0.70      0.71        50\n",
            "weighted avg       0.79      0.74      0.74        50\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer_bow = CountVectorizer(\n",
        "    ngram_range=(1,2),\n",
        "    min_df=2,\n",
        "    max_df=0.95,\n",
        ")\n",
        "\n",
        "X_train_bow = vectorizer_bow.fit_transform(X_train)\n",
        "X_test_bow = vectorizer_bow.transform(X_test)\n",
        "\n",
        "model_lr = LogisticRegression(\n",
        "    max_iter=300,\n",
        "    C=2.0,\n",
        "    penalty='l2',\n",
        "    solver='liblinear',\n",
        "    class_weight='balanced',\n",
        "    random_state=42\n",
        ")\n",
        "model_lr.fit(X_train_bow, y_train)\n",
        "\n",
        "pred3 = model_lr.predict(X_test_bow)\n",
        "acc3 = accuracy_score(y_test, pred3)\n",
        "\n",
        "print(\"BoW + Logistic Regression\")\n",
        "print(\"Akurasi:\", acc3)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, pred3, digits=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faLTfcnqYYct",
        "outputId": "de82d682-2e0d-4002-a43a-ada8c1b21944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BoW + Logistic Regression\n",
            "Akurasi: 0.76\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif     0.8824    0.7500    0.8108        20\n",
            "      netral     0.8571    0.5455    0.6667        11\n",
            "     positif     0.6538    0.8947    0.7556        19\n",
            "\n",
            "    accuracy                         0.7600        50\n",
            "   macro avg     0.7978    0.7301    0.7443        50\n",
            "weighted avg     0.7900    0.7600    0.7581        50\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2vec"
      ],
      "metadata": {
        "id": "bijn0cm4ZxAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenisasi kalimat\n",
        "sentences = [text.split() for text in X_train]\n",
        "\n",
        "# Training Word2Vec\n",
        "w2v_size = 100  # dimensi vektor\n",
        "w2v_model = Word2Vec(\n",
        "    sentences,\n",
        "    vector_size=w2v_size,\n",
        "    window=5,\n",
        "    min_count=1,\n",
        "    workers=4,\n",
        "    epochs=100\n",
        ")\n",
        "\n",
        "# Fungsi untuk membuat representasi dokumen (average Word2Vec)\n",
        "def get_avg_w2v(docs, w2v_model, size):\n",
        "    vecs = []\n",
        "    for doc in docs:\n",
        "        words = doc.split()\n",
        "        word_vecs = []\n",
        "        for word in words:\n",
        "            if word in w2v_model.wv:\n",
        "                word_vecs.append(w2v_model.wv[word])\n",
        "        if len(word_vecs) > 0:\n",
        "            vecs.append(np.mean(word_vecs, axis=0))\n",
        "        else:\n",
        "            vecs.append(np.zeros(size))\n",
        "    return np.array(vecs)\n",
        "\n",
        "# Representasi dokumen\n",
        "X_train_w2v = get_avg_w2v(X_train, w2v_model, w2v_size)\n",
        "X_test_w2v = get_avg_w2v(X_test, w2v_model, w2v_size)\n",
        "\n",
        "# SVM Model\n",
        "model_svm = SVC(kernel=\"linear\")\n",
        "model_svm.fit(X_train_w2v, y_train)\n",
        "\n",
        "pred = model_svm.predict(X_test_w2v)\n",
        "\n",
        "accuracy = accuracy_score(y_test, pred)\n",
        "\n",
        "print(\"Word2Vec + SVM\")\n",
        "print(\"Akurasi:\", accuracy)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6bjyJydGKu5",
        "outputId": "df50b8d4-d845-4d4a-fbc8-9b835b8ed11b"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec + SVM\n",
            "Akurasi: 0.56\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.50      0.85      0.63        20\n",
            "      netral       0.00      0.00      0.00        11\n",
            "     positif       0.69      0.58      0.63        19\n",
            "\n",
            "    accuracy                           0.56        50\n",
            "   macro avg       0.40      0.48      0.42        50\n",
            "weighted avg       0.46      0.56      0.49        50\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}